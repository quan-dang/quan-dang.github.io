<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Deploy tool sử dụng Helm</title>
      <link href="2022/05/06/deploy-tool-with-helm/"/>
      <url>2022/05/06/deploy-tool-with-helm/</url>
      
        <content type="html"><![CDATA[<p>Kubeflow là một open-source ML platform với rất nhiều tính năng có sẵn. Tuy nhiên, tuỳ vào các bài toán cụ thể của công ty mà phát sinh nhu cầu deploy thêm các công cụ khác, ví dụ MLFlow và Seldon Core, .v.v.</p><p>Bài blog này sẽ hướng dẫn mọi người sử dụng Helm để deploy MLFlow lên cluster kubeflow.</p><h3 id="1-Helm-la-gi"><a href="#1-Helm-la-gi" class="headerlink" title="1. Helm là gì?"></a>1. Helm là gì?</h3><p>Helm là một công cụ cho phép install, upgrade, rollback và remove một ứng dụng trên nền tàng k8s một cách dễ dàng. Helm chart là tập hợp các file YAML template và config cần thiết để cài đặt ứng dụng.</p><h3 id="2-Deploy-MLFlow-su-dung-helm"><a href="#2-Deploy-MLFlow-su-dung-helm" class="headerlink" title="2. Deploy MLFlow sử dụng helm"></a>2. Deploy MLFlow sử dụng helm</h3><p>Helm chart cho MLFlow sẽ bao gồm các file sau:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── Chart.yaml</span><br><span class="line">├── docker</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── templates</span><br><span class="line">│   ├── _helpers.tpl</span><br><span class="line">│   ├── deployment.yaml</span><br><span class="line">│   ├── secret.yaml</span><br><span class="line">│   └── service.yaml</span><br><span class="line">└── values.yaml</span><br></pre></td></tr></table></figure><p>Để cài đặt MLFlow chỉ cần sử dụng command sau:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install mlflow -f values.yaml .</span><br></pre></td></tr></table></figure><p>Để gỡ cài đặt</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm remove mlflow</span><br></pre></td></tr></table></figure><p>Một số command hữu ích khác:</p><ul><li>rollback về version nào đó<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm rollback mlflow</span><br></pre></td></tr></table></figure></li><li>kiểm tra các ứng dụng đã deploy bằng helm (còn gọi là release)<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm ls</span><br></pre></td></tr></table></figure></li></ul><h3 id="3-Quan-ly-nhieu-helm-charts-voi-helmfile"><a href="#3-Quan-ly-nhieu-helm-charts-voi-helmfile" class="headerlink" title="3. Quản lý nhiều helm charts với helmfile"></a>3. Quản lý nhiều helm charts với helmfile</h3><p>Khi chúng ta có nhiều helm charts thì làm sao để thiết kế CI/CD tự động install/upgrade các ứng dụng mỗi khi có thay đổi ở các YAML file? Helmfile giúp đơn giản hoá công việc này với command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helmfile -e nonprod apply</span><br></pre></td></tr></table></figure><p>Ở command trên có thêm argument <code>-e nonprod</code> để chỉ định tới apply cho môi trường nonprod.</p><p>Cấu trúc của một repo với helmfile và nhiều helm charts có thể thiết kế như sau:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── contrib</span><br><span class="line">│   └── mlflow</span><br><span class="line">│       ├── Chart.yaml</span><br><span class="line">│       ├── docker</span><br><span class="line">│       │   └── Dockerfile</span><br><span class="line">│       └── templates</span><br><span class="line">│           ├── _helpers.tpl</span><br><span class="line">│           ├── deployment.yaml</span><br><span class="line">│           ├── secret.yaml</span><br><span class="line">│           └── service.yaml</span><br><span class="line">├── deploy.sh</span><br><span class="line">├── helmfile.yaml</span><br><span class="line">└── values</span><br><span class="line">    ├── nonprod</span><br><span class="line">    │   └── values.yaml</span><br><span class="line">    └── prod</span><br><span class="line">        └── values.yaml</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Advanced Model Serving sử dụng Seldon Core (P.2)</title>
      <link href="2022/04/07/advanced-model-serving-using-seldon-core-and-kubernetes-p2/"/>
      <url>2022/04/07/advanced-model-serving-using-seldon-core-and-kubernetes-p2/</url>
      
        <content type="html"><![CDATA[<p>Hello cả nhà =)) sau bao nhiêu ngày ở ẩn, mình đã quyết định trở lại với phần 2 của model serving sử dụng Seldon Core. Phần này sẽ có những chủ đề sau:</p><ul><li>Autoscale model serving với KEDA</li><li>Customize metrics cho Prometheus</li><li>REST Health endpoint</li></ul><h3 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h3><h4 id="1-Horizontal-Pod-Autoscaler-HPA"><a href="#1-Horizontal-Pod-Autoscaler-HPA" class="headerlink" title="1. Horizontal Pod Autoscaler (HPA)"></a>1. Horizontal Pod Autoscaler (HPA)</h4><p>HPA object trong Kubernetes (k8s) được sử dụng để tự động tăng/giảm số lượng pod trong 1 deployment, replica set, hoặc statefulset dựa trên các metrics được định nghĩa sẵn trong manifest bao gồm CPU/memory utilization, hoặc một custom metric khác. Loại scale này gọi là horizontal scale, còn tăng cấu hình CPU, memory, storage, .v.v. thì gọi là vertical scale.<br>Dưới đây là ví dụ về một HPA manifest:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">maxReplicas:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">minReplicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">scaleTargetRef:</span></span><br><span class="line">    <span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line">  <span class="attr">targetCPUUtilizationPercentage:</span> <span class="number">50</span></span><br></pre></td></tr></table></figure><p>HPA trên sẽ tự động thay đổi số lượng pod cho deployment <code>hello-world</code> dựa trên <code>mean CPU utilization percentage</code> của tất cả các pod. HPA cũng đảm bảo số lượng pod tối thiếu là 1, và tối đa là 10. Về cơ chế scale của HPA, mọi người xem thêm tại <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details">đây</a></p><h4 id="2-KEDA"><a href="#2-KEDA" class="headerlink" title="2. KEDA"></a>2. KEDA</h4><p>KEDA (Kubernetes-based Event Driven Autoscaler) mở rộng HPA, cho phép scale workload thông qua external metrics, ví dụ metrics từ Prometheus query.<br>KEDA có 3 thành phần chính:</p><ul><li><strong>Scaler:</strong> kết nối với external source và fetch metrics</li><li><strong>Controller:</strong> scale pod từ/xuống 0 và tạo HPA</li><li><strong>Metrics Adapter:</strong> biên dịch external metrics sang dạng HPA có thể hiểu được, mình cảm thấy đây là một chức năng khá quan trọng, cho phép người dùng không cần tự viết custom metrics phức tạp trực tiếp trên HPA</li></ul><img src="keda-arch.png" alt="KEDA arch" width="800" height="500" /><h3 id="I-Horizontal-scale-model-deployment-voi-KEDA"><a href="#I-Horizontal-scale-model-deployment-voi-KEDA" class="headerlink" title="I. Horizontal scale model deployment với KEDA"></a>I. Horizontal scale model deployment với KEDA</h3><h4 id="1-Cai-dat-KEDA"><a href="#1-Cai-dat-KEDA" class="headerlink" title="1. Cài đặt KEDA"></a>1. Cài đặt KEDA</h4><p>Cài đặt KEDA khá đơn giản chỉ với một vài command như sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">helm repo add kedacore https://kedacore.github.io/charts</span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line">kubectl create namespace keda</span><br><span class="line">helm install keda kedacore/keda --namespace keda</span><br></pre></td></tr></table></figure><p>Để sử dụng KEDA với Seldon Core thì mọi người thêm flag <code>--set keda.enabled=true</code> lúc cài đặt</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">helm install seldon-core seldon-core-operator \</span><br><span class="line">    --repo https://storage.googleapis.com/seldon-charts \</span><br><span class="line">    --<span class="built_in">set</span> usageMetrics.enabled=<span class="literal">true</span> \</span><br><span class="line">    --<span class="built_in">set</span> istio.enabled=<span class="literal">true</span> \</span><br><span class="line">    --namespace seldon-system \</span><br><span class="line">    --<span class="built_in">set</span> keda.enabled=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h4 id="2-Su-dung-KEDA"><a href="#2-Su-dung-KEDA" class="headerlink" title="2. Sử dụng KEDA"></a>2. Sử dụng KEDA</h4><p>Sử dụng KEDA để autoscale các Seldon deployments khá đơn giản, chỉ cần thêm <code>kedaSpec</code> để mô tả cách mà mọi người muốn scale</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># seldon.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">machinelearning.seldon.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SeldonDeployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sklearn</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">models</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">iris</span></span><br><span class="line">  <span class="attr">predictors:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">componentSpecs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">classifier</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">yourdockerusername/demo-seldon:0.0.1</span></span><br><span class="line">        <span class="attr">serviceAccountName:</span> <span class="string">yourserviceaccount</span></span><br><span class="line">      <span class="attr">kedaSpec:</span></span><br><span class="line">        <span class="attr">pollingInterval:</span> <span class="number">15</span>                                <span class="comment"># Optional. Default: 30 seconds</span></span><br><span class="line">        <span class="attr">minReplicaCount:</span> <span class="number">1</span>                                 <span class="comment"># Optional. Default: 0</span></span><br><span class="line">        <span class="attr">maxReplicaCount:</span> <span class="number">3</span>                                 <span class="comment"># Optional. Default: 100</span></span><br><span class="line">        <span class="attr">triggers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">prometheus</span></span><br><span class="line">            <span class="attr">metadata:</span></span><br><span class="line">            <span class="comment"># Required</span></span><br><span class="line">            <span class="attr">serverAddress:</span> <span class="string">http://prometheus-server.monitoring.svc.cluster.local</span></span><br><span class="line">            <span class="attr">metricName:</span> <span class="string">access_frequency</span></span><br><span class="line">            <span class="attr">threshold:</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">            <span class="attr">query:</span> <span class="string">rate(seldon_api_executor_client_requests_seconds_count&#123;seldon_app=~&quot;sklearn&quot;&#125;[10s]</span></span><br><span class="line">    <span class="attr">graph:</span></span><br><span class="line">      <span class="attr">children:</span> []</span><br><span class="line">      <span class="attr">endpoint:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">REST</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">classifier</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">MODEL</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">default</span></span><br></pre></td></tr></table></figure><p>Sau khi <code>apply</code> manifest trên, <code>seldon-controller-manager</code> sẽ khởi tạo 1 object <code>Seldon Deployment</code>. Object này sẽ tạo 1 <code>ScaledObject</code> tương đương với cấu hình scale được định nghĩa trong <code>kedaSpec</code>: số pod tối thiếu là 1 và tối đa là 3, thực hiện query <code>prometheus-server</code> 15s một lần, và threshold để quyết định scale là 10.</p><h3 id="II-Customize-metrics-cho-Prometheus"><a href="#II-Customize-metrics-cho-Prometheus" class="headerlink" title="II. Customize metrics cho Prometheus"></a>II. Customize metrics cho Prometheus</h3><p>Bên cạnh default metrics expose bởi <code>service orchestrator (executor)</code>, ví dụ <code>seldon_api_executor_client_requests_seconds_count</code> ở trên, chúng ta hoàn toàn có thể thêm custom metrics bằng cách thêm 1 method <code>metrics</code> như sau:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelWithMetrics</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Initialising&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self,X,features_names</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Predict called&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">metrics</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;COUNTER&quot;</span>, <span class="string">&quot;key&quot;</span>: <span class="string">&quot;mycounter&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">1</span>&#125;, <span class="comment"># a counter which will increase by the given value</span></span><br><span class="line">            &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;GAUGE&quot;</span>, <span class="string">&quot;key&quot;</span>: <span class="string">&quot;mygauge&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">100</span>&#125;,   <span class="comment"># a gauge which will be set to given value</span></span><br><span class="line">            &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;TIMER&quot;</span>, <span class="string">&quot;key&quot;</span>: <span class="string">&quot;mytimer&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">20.2</span>&#125;,  <span class="comment"># a timer which will add sum and count metrics - assumed millisecs</span></span><br><span class="line">        ]</span><br></pre></td></tr></table></figure><h3 id="III-REST-health-endpoint"><a href="#III-REST-health-endpoint" class="headerlink" title="III. REST health endpoint"></a>III. REST health endpoint</h3><p>Health checks hay probes được sử dụng bởi kubelet để xác định khi nào restart 1 container (liveness probe), sử dụng bởi các services và deployments để xác định pod đã sẵn sàng nhận traffic chưa.</p><p>Chúng ta có thể implement method <code>health_status</code> như sau:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelWithHealthEndpoint</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X, features_names</span>):</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">health_status</span>(<span class="params">self</span>):</span></span><br><span class="line">        response = self.predict([<span class="number">1</span>, <span class="number">2</span>], [<span class="string">&quot;f1&quot;</span>, <span class="string">&quot;f2&quot;</span>])</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(response) == <span class="number">2</span>, <span class="string">&quot;health check returning bad predictions&quot;</span> <span class="comment"># or some other simple validation</span></span><br><span class="line">        <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure><p>Và ghi đè cấu hình default liveness/readiness probes mặc định:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">SeldonDeployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sklearn</span></span><br><span class="line">  <span class="attr">predictors:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">componentSpecs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">yourdockerusername/demo-seldon:0.0.1</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">classifier</span></span><br><span class="line">          <span class="attr">livenessProbe:</span></span><br><span class="line">            <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">60</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">5</span></span><br><span class="line">            <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/health/status</span></span><br><span class="line">              <span class="attr">port:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">readinessProbe:</span></span><br><span class="line">            <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">20</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">5</span></span><br><span class="line">            <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/health/status</span></span><br><span class="line">              <span class="attr">port:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>Chúng ta cũng có thể tự xác định xem model vừa deploy có chạy ngon lành không bằng cách gọi tới route <code>/health/status</code> hoặc <code>/health/ping</code>.</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://cloud.redhat.com/blog/kubernetes-autoscaling-3-common-methods-explained">https://cloud.redhat.com/blog/kubernetes-autoscaling-3-common-methods-explained</a><br>[2] <a href="https://cloudblogs.microsoft.com/opensource/2020/05/12/scaling-kubernetes-keda-intro-kubernetes-based-event-driven-autoscaling/">https://cloudblogs.microsoft.com/opensource/2020/05/12/scaling-kubernetes-keda-intro-kubernetes-based-event-driven-autoscaling/</a><br>[3] <a href="https://viblo.asia/p/kubernetes-practice-kubernetes-based-event-driven-autoscaler-3Q75wAG9ZWb">https://viblo.asia/p/kubernetes-practice-kubernetes-based-event-driven-autoscaler-3Q75wAG9ZWb</a><br>[4] <a href="https://kubebyexample.com/en/concept/health-checks">https://kubebyexample.com/en/concept/health-checks</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Advanced Model Serving sử dụng Seldon Core (P.1)</title>
      <link href="2022/01/16/advanced-model-serving-using-seldon-core-and-kubernetes-p1/"/>
      <url>2022/01/16/advanced-model-serving-using-seldon-core-and-kubernetes-p1/</url>
      
        <content type="html"><![CDATA[<p>Như đề cập ở bài blog <a href="https://quan-dang.github.io/2021/10/30/model-serving-using-bentoml/">trước</a>, mặc dù là một framework đơn giản và mạnh mẽ, song BentoML chưa hỗ trợ một số features hay ho như horizontal scaling, hay blue-green deployment. Seldon Core có thể được sử dụng như một giải pháp thay thế, tuy nhiên yêu cầu nhiều kiến thức hơn về Devops cũng như Kubernetes.</p><img src="bentoml_vs_seldon.jpeg" alt="Bentoml vs Seldon meme" width="500" height="500" /><h3 id="1-Seldon-Core"><a href="#1-Seldon-Core" class="headerlink" title="1. Seldon Core"></a>1. Seldon Core</h3><p>Seldon Core là một framework giúp đóng gói và deploy các model trên Kubernetes một cách dễ dàng. Công cụ này cũng hỗ trợ nhiều features nâng cao như: monitoring, logging, explainers, AB test, vân vân và mây mây.</p><h3 id="2-Quick-start"><a href="#2-Quick-start" class="headerlink" title="2. Quick start"></a>2. Quick start</h3><p>Seldon Core cung cấp sẵn prepackaged server, cho phép user chỉ cần định nghĩa đường dẫn tới model weight (<strong>Line 12</strong>) và deploy. Đường dẫn này cần chứa 2 files sau: <code>model.joblib</code> (model weight), và <code>metadata.yaml</code> (lưu metadata của model, optional)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># metadata.yaml</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">iris</span></span><br><span class="line"><span class="attr">versions:</span> [<span class="string">iris/v1</span>]</span><br><span class="line"><span class="attr">platform:</span> <span class="string">sklearn</span></span><br><span class="line"><span class="attr">inputs:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">datatype:</span> <span class="string">BYTES</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">input</span></span><br><span class="line">  <span class="attr">shape:</span> [ <span class="number">4</span> ]</span><br><span class="line"><span class="attr">outputs:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">datatype:</span> <span class="string">BYTES</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">output</span></span><br><span class="line">  <span class="attr">shape:</span> [ <span class="number">3</span> ]</span><br></pre></td></tr></table></figure><p>Hãy thử deploy service đầu tiên với Seldon Core bằng cách <em>apply</em> file dưới đây nào các bác</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># seldon.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">machinelearning.seldon.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SeldonDeployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sklearn</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">models</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">iris</span></span><br><span class="line">  <span class="attr">predictors:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">graph:</span></span><br><span class="line">      <span class="attr">children:</span> []</span><br><span class="line">      <span class="attr">implementation:</span> <span class="string">SKLEARN_SERVER</span></span><br><span class="line">      <span class="attr">modelUri:</span> <span class="string">gs://seldon-models/v1.13.0-dev/sklearn/iris</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">classifier</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">replicas:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>Lưu ý một số thông tin quan trọng ở file trên:</p><ul><li><strong>Line 43:</strong> Chúng ta chọn SKLEARN_SERVER, do <code>model.joblib</code> là model sklearn</li><li><strong>Line 47:</strong> Số lượng pod cho service trên là 1 (chúng ta sẽ học cách tự động thay đổi số lượng replica trong những phần sau)</li></ul><p>Bây giờ hãy thử port-forward service và test API nào</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl port-forward svc/sklearn-default-classifier -n models 9000:9000</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ curl -d <span class="string">&#x27;&#123;&quot;data&quot;: &#123;&quot;ndarray&quot;:[[1.0, 2.0, 5.0, 6.0]]&#125;&#125;&#x27;</span>\</span><br><span class="line">    -X POST http://localhost:9000/api/v1.0/predictions\</span><br><span class="line">    -H <span class="string">&quot;Content-Type: application/json&quot;</span></span><br><span class="line">&#123;<span class="string">&quot;data&quot;</span>:&#123;<span class="string">&quot;names&quot;</span>:[<span class="string">&quot;t:0&quot;</span>,<span class="string">&quot;t:1&quot;</span>,<span class="string">&quot;t:2&quot;</span>],<span class="string">&quot;ndarray&quot;</span>:[[9.912315378486697e-07,0.0007015931307746079,0.9992974156376876]]&#125;,<span class="string">&quot;meta&quot;</span>:&#123;<span class="string">&quot;requestPath&quot;</span>:&#123;<span class="string">&quot;classifier&quot;</span>:<span class="string">&quot;sklearnserver:1.9.1&quot;</span>&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://localhost:9000/api/v1.0/metadata</span><br><span class="line">&#123;<span class="string">&quot;custom&quot;</span>:&#123;&#125;,<span class="string">&quot;inputs&quot;</span>:[&#123;<span class="string">&quot;datatype&quot;</span>:<span class="string">&quot;BYTES&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;input&quot;</span>,<span class="string">&quot;shape&quot;</span>:[4]&#125;],<span class="string">&quot;name&quot;</span>:<span class="string">&quot;iris&quot;</span>,<span class="string">&quot;outputs&quot;</span>:[&#123;<span class="string">&quot;datatype&quot;</span>:<span class="string">&quot;BYTES&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;output&quot;</span>,<span class="string">&quot;shape&quot;</span>:[3]&#125;],<span class="string">&quot;platform&quot;</span>:<span class="string">&quot;sklearn&quot;</span>,<span class="string">&quot;versions&quot;</span>:[<span class="string">&quot;iris/v1&quot;</span>]&#125;</span><br></pre></td></tr></table></figure><h3 id="3-Custom-model-server"><a href="#3-Custom-model-server" class="headerlink" title="3. Custom model server"></a>3. Custom model server</h3><p>Sử dụng prepackaged model server giúp chúng ta chỉ cần quan tâm tới training model để ra được weight, mà không cần quan tâm tới việc code phần API cho model inference. Tuy nhiên, trong thực tế, đôi khi model inference không chỉ đơn giản là <code>clf.predict()</code>, và khi đó chúng ta cần phải customize model server như ví dụ bên dưới.</p><p>Cấu trúc thư mục của ví dụ này như sau:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">custom-server/</span><br><span class="line">|____requirements.txt</span><br><span class="line">|____Dockerfile</span><br><span class="line">|____deploy</span><br><span class="line">| |____seldon.yaml <span class="comment"># file yaml để deploy</span></span><br><span class="line">| |____deploy.sh <span class="comment"># script để apply file yaml</span></span><br><span class="line">|____constants.py <span class="comment"># các constants dùng trong code inference</span></span><br><span class="line">|____push.sh <span class="comment"># script để build và push docker image</span></span><br><span class="line">|____utils</span><br><span class="line">| |______init__.py</span><br><span class="line">| |____gcs_utils.py <span class="comment"># chứa các utils script, ví dụ download file từ GCS</span></span><br><span class="line">|____online_score_api.py <span class="comment"># code inference</span></span><br></pre></td></tr></table></figure><p>Trước hết chúng ta sẽ chuẩn bị phần inference code để xử lý các request tới API</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># online_score_api.py</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">online_score_api</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.root_path = <span class="string">&quot;/mnt/model&quot;</span></span><br><span class="line">        self.load()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">self</span>):</span></span><br><span class="line">        local_model_path = os.path.join(self.root_path, constants.MODEL_FILE)</span><br><span class="line">        logging.info(<span class="string">&quot;downloading model file&quot;</span>)</span><br><span class="line">        gcs_utils.download_file_from_gcs(gcs_bucket_name=constants.GCS_BUCKET_NAME, </span><br><span class="line">                                    gcs_blob_object=os.path.join(constants.GCS_BLOB_OBJECT, constants.MODEL_FILE),</span><br><span class="line">                                    local_model_path=local_model_path)</span><br><span class="line">        self._joblib = joblib.load(local_model_path)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X, names=[], meta=[]</span>):</span></span><br><span class="line">        logging.info(<span class="string">f&quot;model features: <span class="subst">&#123;X&#125;</span>&quot;</span>)</span><br><span class="line">        logging.info(<span class="string">f&quot;model names: <span class="subst">&#123;names&#125;</span>&quot;</span>)</span><br><span class="line">        logging.info(<span class="string">f&quot;model meta: <span class="subst">&#123;meta&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            result = self._joblib.predict(X)</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">            logging.exception(<span class="string">&quot;Exception during predict&quot;</span>)</span><br></pre></td></tr></table></figure><p>Seldon Core hỗ trợ build 2 loại model server: <em>reusable</em> và <em>non-reusable</em>. Ở ví dụ trên, <strong>Line 6</strong> load từ GCS (remote storage) nên là <em>reusable</em> server, nếu load từ file trong image thì sẽ là <em>non-reusable</em>. Hàm <code>load()</code> được đặt trong hàm <code>__init__()</code> do chúng ta muốn load model một lần, trong khi khởi tạo pod. </p><p>Cuối cùng chúng ta sẽ viết hàm <code>predict()</code> như <strong>Line 16</strong> để mỗi khi có request tới thì hàm này sẽ xử lý. Các bác có thể thấy hàm này nhận 3 params là:</p><ul><li><strong>X:</strong> (prediction data đã được Seldon Core tự động chuyển đổi qua dạng numpy array)</li><li><strong>names:</strong> tên của các cột tương ứng trong X</li><li><strong>meta:</strong> các thông tin khác</li></ul><p>Một lưu ý cho các bác nếu không muốn bị Seldon tự động chuyển input sang dạng <code>numpy array</code> (hoặc đôi khi Seldon không thể chuyển qua dạng <code>numpy array</code>), thì các bác chỉ cần thay hàm <code>predict()</code> bằng <code>predict_raw()</code> là được nha.</p><p>Tiếp theo chúng ta sẽ chuẩn bị một file <strong>Dockerfile</strong> đơn giản, giúp package đoạn code inference trên thành Docker image để đem đi deploy.</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dockerfile</span></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">3.7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /mnt/model/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod -R a+rw /mnt/model/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> . /app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pip install -r requirements.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Port for REST</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">9000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define environment variable</span></span><br><span class="line"><span class="keyword">ENV</span> MODEL_NAME online_score_api</span><br><span class="line"><span class="keyword">ENV</span> SERVICE_TYPE MODEL</span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> <span class="built_in">exec</span> seldon-core-microservice <span class="variable">$MODEL_NAME</span> --service-type <span class="variable">$SERVICE_TYPE</span></span></span><br></pre></td></tr></table></figure><p><strong>Note:</strong> Các bác chú ý cấp quyền <code>rw</code> tới thư mục <code>/mnt/model</code> (<strong>Line 5</strong>) để có thể lưu model nha, nếu không thì sẽ bị lỗi permission. OK! Giờ thì sửa file YAML để đem đi <em>apply</em>, tương tự như prepackaged server nào.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># seldon.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">machinelearning.seldon.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SeldonDeployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sklearn</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">models</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">iris</span></span><br><span class="line">  <span class="attr">predictors:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">componentSpecs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">classifier</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">yourdockerusername/demo-seldon:0.0.1</span></span><br><span class="line">        <span class="attr">serviceAccountName:</span> <span class="string">yourserviceaccount</span></span><br><span class="line">    <span class="attr">graph:</span></span><br><span class="line">      <span class="attr">children:</span> []</span><br><span class="line">      <span class="attr">endpoint:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">REST</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">classifier</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">MODEL</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">replicas:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>Ở <strong>Line 15</strong> các bác điền service account phù hợp để service có quyền kéo model từ GCS về nha. Tận hưởng thành quả thôi nào!</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ curl -d <span class="string">&#x27;&#123;&quot;data&quot;: &#123;&quot;names&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;],</span></span><br><span class="line"><span class="string">            &quot;ndarray&quot;: [[1.0, 2.0, 5.0, 6.0]]&#125;,</span></span><br><span class="line"><span class="string">            &quot;meta&quot;: &#123;&quot;anotherParam&quot;: &quot;anotherParamValue&quot;&#125;&#125;&#x27;</span>\</span><br><span class="line">    -X POST http://localhost:9000/api/v1.0/predictions\</span><br><span class="line">    -H <span class="string">&quot;Content-Type: application/json&quot;</span></span><br><span class="line">&#123;<span class="string">&quot;data&quot;</span>:&#123;<span class="string">&quot;names&quot;</span>:[],<span class="string">&quot;ndarray&quot;</span>:[2]&#125;,<span class="string">&quot;meta&quot;</span>:&#123;<span class="string">&quot;requestPath&quot;</span>:&#123;<span class="string">&quot;classifier&quot;</span>:<span class="string">&quot;yourdockerusername/demo-seldon:0.0.1&quot;</span>&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><p>Bây giờ chúng ta sẽ chuẩn bị phần reponse cho <code>/metadata</code> endpoint bằng cách thêm hàm <code>init_metadata</code> trong code inference</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">online_score_api</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_metadata</span>(<span class="params">self</span>):</span></span><br><span class="line">        logging.info(<span class="string">&quot;metadata method called&quot;</span>)</span><br><span class="line">        meta = &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;iris-sklearn&quot;</span>,</span><br><span class="line">            <span class="string">&quot;versions&quot;</span>: [<span class="string">&quot;v0.0.1&quot;</span>],</span><br><span class="line">            <span class="string">&quot;platform&quot;</span>: <span class="string">&quot;seldon&quot;</span>,</span><br><span class="line">            <span class="string">&quot;inputs&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">&quot;messagetype&quot;</span>: <span class="string">&quot;tensor&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;schema&quot;</span>: &#123;<span class="string">&quot;names&quot;</span>: [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>], <span class="string">&quot;shape&quot;</span>: [<span class="number">4</span>]&#125;,</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="string">&quot;outputs&quot;</span>: [&#123;<span class="string">&quot;messagetype&quot;</span>: <span class="string">&quot;tensor&quot;</span>, <span class="string">&quot;schema&quot;</span>: &#123;<span class="string">&quot;shape&quot;</span>: [<span class="number">1</span>]&#125;&#125;],</span><br><span class="line">            <span class="string">&quot;custom&quot;</span>: &#123;<span class="string">&quot;author&quot;</span>: <span class="string">&quot;quandv&quot;</span>, <span class="string">&quot;extra&quot;</span>: <span class="string">&quot;information&quot;</span>&#125;,</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> meta</span><br><span class="line"></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>Khi đó response của route <code>/metadata</code> sẽ tương tự như sau</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&quot;custom&quot;</span>:&#123;<span class="string">&quot;author&quot;</span>:<span class="string">&quot;seldon-dev&quot;</span>,<span class="string">&quot;extra&quot;</span>:<span class="string">&quot;information&quot;</span>&#125;,<span class="string">&quot;inputs&quot;</span>:[&#123;<span class="string">&quot;messagetype&quot;</span>:<span class="string">&quot;tensor&quot;</span>,<span class="string">&quot;schema&quot;</span>:&#123;<span class="string">&quot;names&quot;</span>:[<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>,<span class="string">&quot;d&quot;</span>],<span class="string">&quot;shape&quot;</span>:[4]&#125;&#125;],<span class="string">&quot;name&quot;</span>:<span class="string">&quot;iris-sklearn&quot;</span>,<span class="string">&quot;outputs&quot;</span>:[&#123;<span class="string">&quot;messagetype&quot;</span>:<span class="string">&quot;tensor&quot;</span>,<span class="string">&quot;schema&quot;</span>:&#123;<span class="string">&quot;shape&quot;</span>:[1]&#125;&#125;],<span class="string">&quot;platform&quot;</span>:<span class="string">&quot;seldon&quot;</span>,<span class="string">&quot;versions&quot;</span>:[<span class="string">&quot;v0.0.1&quot;</span>]&#125;</span><br></pre></td></tr></table></figure><p>Trên đây là các bước cơ bản để các bác có thể deploy một model lên cụm Kubernetes. Ở các phần sau chúng ta sẽ cùng nhau tìm hiểu thêm một số features thú vị khác mà Seldon cung cấp nha. Ví dụ cái monitoring dashboard như sau:</p><img src="seldon_monitoring_dashboard.png" alt="Seldon monitoring dashboard" width="800" height="400" /><p>Code về tutorial các bác có thể xem ở đây: <a href="https://github.com/quan-dang/seldon-tutorials">https://github.com/quan-dang/seldon-tutorials</a></p><h3 id="4-Tai-lieu-tham-khao"><a href="#4-Tai-lieu-tham-khao" class="headerlink" title="4. Tài liệu tham khảo"></a>4. Tài liệu tham khảo</h3><p>[1] <a href="https://github.com/SeldonIO/seldon-core">https://github.com/SeldonIO/seldon-core</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Model Serving sử dụng BentoML</title>
      <link href="2021/10/30/model-serving-using-bentoml/"/>
      <url>2021/10/30/model-serving-using-bentoml/</url>
      
        <content type="html"><![CDATA[<div style="text-align: center"> Khi mà một model đã được train xong và đáp ứng được yêu cầu cả về business lẫn technical, thì đây chính là lúc đem lên môi trường production. Giai đoạn này được gọi là model serving. </div><img src="model-serving-meme.jpeg" alt="Model serving meme" width="500" height="500" /><br /><p>Có nhiều hình thức để serve một model, và cũng có nhiều tool/framework hỗ trợ chúng ta làm điều này.</p><h3 id="1-Cac-hinh-thuc-serving"><a href="#1-Cac-hinh-thuc-serving" class="headerlink" title="1. Các hình thức serving"></a>1. Các hình thức serving</h3><ul><li><strong>Offline serving (batch inference)</strong>: model dự đoán trên cả tập dữ liệu test, và lưu kết quả vào 1 database hoặc storage.</li><li><strong>Model as a service:</strong> đóng gói model thành một service và cung cấp API endpoint cho user. User sẽ tạo POST/GET request tới endpoint này để trigger quá trình model inference và nhận về kết quả.</li><li><strong>Edge deployment:</strong> chuyển đổi model thành định dạng phù hợp (ví dụ ONNX) để deploy trên các thiết bị edge (ví dụ: browser, Raspberry Pi, Nvidia Jetson Nano, và Google Coral, …)</li></ul><h3 id="2-Khi-nao-thi-dung-hinh-thuc-serving-nao"><a href="#2-Khi-nao-thi-dung-hinh-thuc-serving-nao" class="headerlink" title="2. Khi nào thì dùng hình thức serving nào"></a>2. Khi nào thì dùng hình thức serving nào</h3><img src="model-serving-comparision.png" alt="Model serving comparisions" width="900" height="300"><h3 id="3-BentoML"><a href="#3-BentoML" class="headerlink" title="3. BentoML"></a>3. BentoML</h3><p>BentoML là một framework hỗ trợ đóng gói và deploy model trên nhiều nền tảng khác nhau, ví dụ:</p><ul><li>Serverless Compute Services như AWS Lambda và Google Cloud Run</li><li>Compute Engine như Amazon EC2</li><li>AI Platform như Amazon SageMaker, VertexAI</li><li>Kubernetes Cluster như Kubeflow</li></ul><p>Bên cạnh đó BentoML cũng cung cấp CLI, Python API và Web UI để quản lý các model trên production.</p><img src="yatai.png" alt="Yatai Web UI" width="700" height="300" /><figcaption align="center" font-size="8px"><i>Source: https://github.com/bentoml/BentoML</i></figcaption><h3 id="4-Quickstart"><a href="#4-Quickstart" class="headerlink" title="4. Quickstart"></a>4. Quickstart</h3><p>Cài đặt BentoML khá đơn giản, chỉ cần chạy command</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install bentoml&#x3D;&#x3D;0.13.1</span><br></pre></td></tr></table></figure><p>Quickstart này sẽ hướng dẫn mọi người cách serve một model SVM đơn giản (train trên dữ liệu Iris) dưới hình thức Model as a service.<br>Project structure của chúng ta sẽ như sau:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bentoml-tutorials&#x2F;</span><br><span class="line">├── bento_service.py      # BentoService definition</span><br><span class="line">├── train.py              # For training and packaging</span><br><span class="line">├── requirements.txt</span><br><span class="line">├── locustfile.py         # For load testing with Locust</span><br><span class="line">├── serve.sh              # For serving model locally</span><br><span class="line">└── test_data             # Testing data</span><br></pre></td></tr></table></figure><p>File <strong>bento_service.py</strong> dùng để định nghĩa BentoService, bao gồm thông tin về model, package dependencies và code để predict</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bentoml <span class="keyword">import</span> env, artifacts, api, BentoService</span><br><span class="line"><span class="keyword">from</span> bentoml.adapters <span class="keyword">import</span> DataframeInput</span><br><span class="line"><span class="keyword">from</span> bentoml.frameworks.sklearn <span class="keyword">import</span> SklearnModelArtifact</span><br><span class="line"></span><br><span class="line"><span class="meta">@env(<span class="params">infer_pip_packages=<span class="literal">True</span></span>) </span><span class="comment"># automatically infer necessary pip packages</span></span><br><span class="line"><span class="meta">@artifacts(<span class="params">[SklearnModelArtifact(<span class="params"><span class="string">&#x27;model&#x27;</span></span>)]</span>) </span><span class="comment"># since our model is scikit-learn based</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IrisClassifier</span>(<span class="params">BentoService</span>):</span></span><br><span class="line"><span class="meta">    @api(<span class="params"><span class="built_in">input</span>=DataframeInput(<span class="params"></span>), batch=<span class="literal">True</span></span>)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, df: pd.DataFrame</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.artifacts.model.predict(df)</span><br></pre></td></tr></table></figure><p>Ở <strong>Line 10</strong>, bằng cách khai báo <code>InputAdapter</code> là <code>DataFrameInput</code>, BentoML sẽ chuyển input cho API sang dạng <code>DataFrame</code> trước khi truyền vào hàm <code>predict</code>. Framework này cũng hỗ trợ một số loại <code>InputAdapter</code> khác để đối ứng với các loại dữ liệu khác nhau, ví dụ như: <code>JsonInput</code>, <code>ImageInput</code>, và <code>TfTensorInput</code>, … (xem thêm tại <a href="https://docs.bentoml.org/en/latest/api/adapters.html#">đây</a>. Khi sử dụng <code>batch=True</code>, chế độ Adaptive Micro Batching sẽ được kích hoạt, cho phép chờ và xử lý nhiều request một lúc thay vì từng request một.</p><p>File <strong>train.py</strong> sẽ dùng để training model, và đóng gói model thành 1 BentoService bundle</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bento_service <span class="keyword">import</span> IrisClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model Training</span></span><br><span class="line">clf = svm.SVC(gamma=<span class="string">&#x27;scale&#x27;</span>)</span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a iris classifier service instance</span></span><br><span class="line">iris_classifier_service = IrisClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pack the newly trained model artifact</span></span><br><span class="line">iris_classifier_service.pack(<span class="string">&#x27;model&#x27;</span>, clf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the prediction service to disk for model serving</span></span><br><span class="line">saved_path = iris_classifier_service.save(version=<span class="string">&quot;0.0.1&quot;</span>)</span><br></pre></td></tr></table></figure><p>Sau khi run file này thì các bác sẽ thấy log ở console tương tự như sau:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BentoService bundle &#39;IrisClassifier:0.0.1&#39; saved to: &#x2F;Users&#x2F;yourusername&#x2F;bentoml&#x2F;repository&#x2F;IrisClassifier&#x2F;0.0.1</span><br></pre></td></tr></table></figure><p>Dưới đây là cấu trúc thư mục của BentoService bundle. Mọi người có thể thấy đoạn code snippet của chúng ta đã được bundle thành rất nhiều file khác để sẵn sàng cho việc đóng gói và deploy mà không cần quá nhiều kiến thức về Docker hay DevOps.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">|____docs.json</span><br><span class="line">|____requirements.txt</span><br><span class="line">|____environment.yml</span><br><span class="line">|____bentoml.yml</span><br><span class="line">|____Dockerfile</span><br><span class="line">|____IrisClassifier</span><br><span class="line">| |____artifacts</span><br><span class="line">| | |______init__.py</span><br><span class="line">| | |____model.pkl</span><br><span class="line">| |____bentoml.yml</span><br><span class="line">| |______init__.py</span><br><span class="line">| |____bento_service.py</span><br><span class="line">| |____zipimports</span><br><span class="line">|____python_version</span><br><span class="line">|____MANIFEST.in</span><br><span class="line">|____README.md</span><br><span class="line">|____setup.py</span><br><span class="line">|____docker-entrypoint.sh</span><br><span class="line">|____bentoml-init.sh</span><br></pre></td></tr></table></figure><p>Bây giờ để start API server chúng ta chỉ cần sử dụng đường dẫn tới bundle vừa nãy như sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bentoml serve /Users/yourusername/bentoml/repository/IrisClassifier/0.0.1 --port 5005</span><br></pre></td></tr></table></figure><p>và sẽ thấy ứng dụng đang run ở port 5005</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ bentoml serve /Users/quandv6/bentoml/repository/IrisClassifier/0.0.1 --port 5005</span><br><span class="line">[2022-01-03 18:25:40,967] INFO - Starting BentoML API proxy <span class="keyword">in</span> development mode..</span><br><span class="line">[2022-01-03 18:25:41,078] INFO - Micro batch enabled <span class="keyword">for</span> API `predict` max-latency: 20000 max-batch-size 4000</span><br><span class="line">[2022-01-03 18:25:41,078] INFO - Your system nofile <span class="built_in">limit</span> is 10496, <span class="built_in">which</span> means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors <span class="keyword">for</span> the server process, or launch more microbatch instances to accept more concurrent connection.</span><br><span class="line">======== Running on http://0.0.0.0:5005 ========</span><br><span class="line">(Press CTRL+C to quit)</span><br><span class="line">[2022-01-03 18:25:41,379] INFO - Starting BentoML API server <span class="keyword">in</span> development mode..</span><br><span class="line"> * Serving Flask app <span class="string">&#x27;IrisClassifier&#x27;</span> (lazy loading)</span><br><span class="line"> * Environment: production</span><br><span class="line">   WARNING: This is a development server. Do not use it <span class="keyword">in</span> a production deployment.</span><br><span class="line">   Use a production WSGI server instead.</span><br><span class="line"> * Debug mode: off</span><br><span class="line"> * Running on http://127.0.0.1:65425/ (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure><p>Thử tạo một request tới API thôi nào!</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ curl -i \                                                                                                    </span><br><span class="line">    --header <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">    --request POST \</span><br><span class="line">    --data <span class="string">&#x27;[[5.1, 3.5, 1.4, 0.2]]&#x27;</span> \</span><br><span class="line">    http://localhost:5005/predict</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Type: application/json</span><br><span class="line">X-Request-Id: 581e7229-ac6d-488a-a672-8b425210ed4e</span><br><span class="line">Content-Length: 3</span><br><span class="line">Date: Mon, 03 Jan 2022 11:16:51 GMT</span><br><span class="line">Server: Python/3.8 aiohttp/3.8.1</span><br><span class="line"></span><br><span class="line">[0]</span><br></pre></td></tr></table></figure><p>Nếu chúng ta truy cập vào đường dẫn <a href="http://localhost:5005/">http://localhost:5005/</a> sẽ thấy Swagger UI, chính là document cho các endpoints hiện tại.</p><img src="swagger-ui.png" alt="Swagger UI" width="600" height="400" /><p>Bây giờ hãy start yatai và vào <a href="http://localhost:5006/">http://localhost:5006</a> để xem thông tin của các model nào </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ bentoml yatai-service-start --ui-port 5006 --grpc-port 5007                                                   </span><br><span class="line">* Starting BentoML YataiService gRPC Server</span><br><span class="line">* Debug mode: off</span><br><span class="line">* Web UI: running on http://127.0.0.1:5006</span><br><span class="line">* Running on 127.0.0.1:5007 (Press CTRL+C to quit)</span><br><span class="line">* Prometheus: running on http://127.0.0.1:5006/metrics</span><br><span class="line"></span><br><span class="line">* Help and instructions: https://docs.bentoml.org/en/latest/guides/yatai_service.html</span><br><span class="line">* Web server <span class="built_in">log</span> can be found here: /Users/quandv6/bentoml/logs/yatai_web_server.log</span><br><span class="line">-----</span><br><span class="line">* Usage <span class="keyword">in</span> Python:</span><br><span class="line">*  bento_svc.save(yatai_url=<span class="string">&quot;127.0.0.1:5007&quot;</span>)</span><br><span class="line">*  from bentoml.yatai.client import get_yatai_client</span><br><span class="line">*  get_yatai_client(<span class="string">&quot;127.0.0.1:5007&quot;</span>).repository.list()</span><br><span class="line">* Usage <span class="keyword">in</span> CLI:</span><br><span class="line">*  bentoml list --yatai-url=127.0.0.1:5007</span><br><span class="line">*  bentoml containerize IrisClassifier:latest --yatai-url=127.0.0.1:5007</span><br><span class="line">*  bentoml push IrisClassifier:20200918001645_CD2886 --yatai-url=127.0.0.1:5007</span><br><span class="line">*  bentoml pull IrisClassifier:20200918001645_CD2886 --yatai-url=127.0.0.1:5007</span><br><span class="line">*  bentoml retrieve IrisClassifier:20200918001645_CD2886 --yatai-url=127.0.0.1:5007 --target_dir=<span class="string">&quot;/tmp/foo/bar&quot;</span></span><br><span class="line">*  bentoml delete IrisClassifier:20200918001645_CD2886 --yatai-url=127.0.0.1:5007</span><br></pre></td></tr></table></figure><img src="yatai-in-practice.png" alt="Yatai In Practice" width="900" height="350" /><p>OK! Thế là chúng ta đã có một model được serve theo hình thức Model as a service, và một model management UI để quản lý các version của model. Triển khai Offline serving với BentoML khá đơn giản với command như sau, với argument là file đầu vào định dạng CSV.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bentoml run IrisClassifier:0.0.1 predict --format csv --input-file test_data/test-offline-batch.csv</span><br></pre></td></tr></table></figure><p>Bản chất của command này là sẽ biến input file CSV thành định dạng <em>DataFrame</em>, và sau đó đưa qua hàm <em>predict</em> định nghĩa trong BentoService IrisClassifier. Các bác tham khảo thêm tại <a href="https://github.com/bentoml/BentoML/blob/0.13-LTS/bentoml/service/inference_api.py#L312">đây</a></p><h3 id="5-Mot-so-luu-y"><a href="#5-Mot-so-luu-y" class="headerlink" title="5. Một số lưu ý"></a>5. Một số lưu ý</h3><h4 id="5-1-Adaptive-Micro-Batching"><a href="#5-1-Adaptive-Micro-Batching" class="headerlink" title="5.1. Adaptive Micro Batching"></a>5.1. Adaptive Micro Batching</h4><p>2 tham số quan trọng cần chú ý khi sử dụng Adaptive Micro Batching:</p><ul><li><strong>mb_max_batch_size:</strong> kích thước tối đa của 1 batch</li><li><strong>mb_max_latency:</strong> thời gian phàn hồi tối đa (đơn vị miliseconds)</li></ul><p>Dựa vào 2 tham số trên, framework sẽ tự điều chỉnh thời gian chờ và kích thước batch sao cho throughput (số lượng request xử lý trong một lần) là lớn nhất và latency (thời gian phản hồi) là nhỏ nhất. Nếu các bác quan tâm về cơ chế tự điều chỉnh này, có thể xem thêm tại <a href="https://github.com/bentoml/BentoML/discussions/927">đây</a>.</p><h4 id="5-2-Monitoring-voi-Prometheus"><a href="#5-2-Monitoring-voi-Prometheus" class="headerlink" title="5.2. Monitoring với Prometheus"></a>5.2. Monitoring với Prometheus</h4><p>Sau khi đã start API server, chúng ta có thể lấy một số metrics có sẵn thông qua <code>/metrics</code> endpoint như sau:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:5005/metrics</span><br></pre></td></tr></table></figure><p>Các bác có thể thêm các metrics khác, ví dụ như <code>request_processing_time</code> như sau</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> prometheus_client <span class="keyword">import</span> Summary</span><br><span class="line"></span><br><span class="line">REQUEST_TIME=Summary(<span class="string">&#x27;request_processing_time&#x27;</span>, <span class="string">&#x27;Time spend processing request&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@env(<span class="params">infer_pip_packages=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="meta">@artifacts(<span class="params">[SklearnModelArtifact(<span class="params"><span class="string">&#x27;model&#x27;</span></span>)]</span>)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IrisClassifier</span>(<span class="params">BentoService</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A minimum prediction service exposing a Scikit-learn model</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @REQUEST_TIME.time()</span></span><br><span class="line"><span class="meta">    @api(<span class="params"><span class="built_in">input</span>=DataframeInput(<span class="params"></span>), batch=<span class="literal">True</span></span>)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, df: pd.DataFrame</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        An inference API named `predict` with Dataframe input adapter, which codifies</span></span><br><span class="line"><span class="string">        how HTTP requests or CSV files are converted to a pandas Dataframe object as the</span></span><br><span class="line"><span class="string">        inference API function input</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.artifacts.model.predict(df)</span><br></pre></td></tr></table></figure><h4 id="5-3-Metadata"><a href="#5-3-Metadata" class="headerlink" title="5.3. Metadata"></a>5.3. Metadata</h4><p>Endpoint <code>/metadata</code> được tạo ra tự động để cung cấp thông tin về model deployment, bao gồm một số trường như tên, ngày tạo, và dependencies, …</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:5005/metadata</span><br></pre></td></tr></table></figure><p>Ngoài ra, chúng ta hoàn toàn có thể thêm các thông tin khác ngoài những thứ có sẵn như sau</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">iris_classifier_service.pack(</span><br><span class="line">    <span class="string">&#x27;model&#x27;</span>, </span><br><span class="line">    clf,</span><br><span class="line">    metadata=&#123;</span><br><span class="line">        <span class="string">&#x27;created_by&#x27;</span>: <span class="string">&#x27;quan.dang&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="6-Nhan-xet"><a href="#6-Nhan-xet" class="headerlink" title="6. Nhận xét"></a>6. Nhận xét</h3><p>BentoML là một framework giúp chúng ta có thể deploy một model dễ dàng và nhanh chóng mà không cần quá nhiều kiến thức về Software Developement và DevOps. Sử dụng BentoML cũng giúp linh hoạt trong việc deploy trên các platform khác nhau, cũng như chuyển giao giữa các platform. Tuy nhiên, framework này cũng có nhược điểm đó là chỉ hỗ trợ đóng gói model, mà không thể tự handle horizontal hay auto-scaling. Muốn khắc phục vấn đề này thì phải kết hợp BentoML với một orchestration framework như Kubernetes hoặc Seldon (chúng ta sẽ tìm hiểu trong các bài sau).</p><p>Code về tutorial các bác có thể xem ở đây: <a href="https://github.com/quan-dang/bentoml-tutorials">https://github.com/quan-dang/bentoml-tutorials</a></p><h3 id="7-Tai-lieu-tham-khao"><a href="#7-Tai-lieu-tham-khao" class="headerlink" title="7. Tài liệu tham khảo"></a>7. Tài liệu tham khảo</h3><ol><li><a href="https://spell.ml/blog/mlops-concepts-model-serving-X385lREAACcAAGzS">https://spell.ml/blog/mlops-concepts-model-serving-X385lREAACcAAGzS</a></li><li><a href="https://mercari.github.io/ml-system-design-pattern">https://mercari.github.io/ml-system-design-pattern</a></li><li><a href="https://neptune.ai/blog/ml-model-serving-best-tools">https://neptune.ai/blog/ml-model-serving-best-tools</a></li><li><a href="https://github.com/bentoml/BentoML">https://github.com/bentoml/BentoML</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> model serving </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kiểm thử hệ thống Machine Learning</title>
      <link href="2021/08/22/test-in-ml/"/>
      <url>2021/08/22/test-in-ml/</url>
      
        <content type="html"><![CDATA[<p>Xin chào mọi người, lại là mình đây, hôm nay chúng mình sẽ cùng nhau tìm hiểu xem để kiểm thử một hệ thống Machine Learning (ML) thì nên làm những gì nào!<br>Thêm cái meme trước khi bắt đầu bài viết như mọi khi phát đã.</p><img src="ml-testing-meme.png" alt="ML testing meme" width="500" height="500" /><h3 id="Kiem-thu-he-thong-ML-de-nhu-an-banh"><a href="#Kiem-thu-he-thong-ML-de-nhu-an-banh" class="headerlink" title="Kiểm thử hệ thống ML dễ như ăn bánh?"></a>Kiểm thử hệ thống ML dễ như ăn bánh?</h3><p>Khác với các hệ thống software truyển thống: một ông developer ngồi nghĩ ra các rule, và lập trình bằng Python, Java, hoặc… LOLCODE, thì ML model sẽ tự sinh ra các rule sử dụng dữ liệu được cung cấp. Điều này đương nhiên là tốt, vì không phải rule nào ông developer cũng nghĩ ra được, tuy nhiên nó cũng có mặt trái của nó: rule được sinh ra có thể thay đổi, theo hướng tốt, xấu, hoặc bị BUG rồi các ông ạ :). Điều này dẫn tới việc kiểm thử và debug một hệ thống ML không hề đơn giản.</p><img src="ml-testing.png" alt="ML testing" width="600" height="70" /><h3 id="Kiem-thu-he-thong-software-truyen-thong"><a href="#Kiem-thu-he-thong-software-truyen-thong" class="headerlink" title="Kiểm thử hệ thống software truyền thống"></a>Kiểm thử hệ thống software truyền thống</h3><p>Thông thường có 2 loại kiểm thử phần mềm:</p><ul><li>Functional Testing: kiểm tra xem hệ thống đã đảm bảo yêu cầu về chức năng chưa, ví dụ ấn tắt windows update mãi mà nó vẫn update thì là fail rồi :)</li><li>Non-functional Testing: kiểm tra xem hệ thống có đáp ứng được kỳ vọng của khách hàng không, ví dụ tất cả người trên thế giới cùng ấn nút tham gia group MLOps VN thì group không được sập chả hạn.</li></ul><h4 id="Functional-Testing"><a href="#Functional-Testing" class="headerlink" title="Functional Testing"></a>Functional Testing</h4><p>Thông thường loại này bao gồm:</p><ol><li><p><strong>Unit testing:</strong> test từng module nhỏ</p></li><li><p><strong>Integration testing:</strong> test một module lớn bao gồm nhiều module nhỏ để đảm bảo khi kết hợp không xảy ra vấn đề gì</p><p> <strong>Mẹo nhỏ:</strong> Theo nguyên tắc <a href="https://people.apache.org/~fhanik/kiss.html">KISS</a>, hãy luôn cố gắng bẻ vấn đề thành nhiều module đủ nhỏ và đủ dễ hiểu. </p><p> Ví dụ dưới đây được trích từ <a href="https://machinelearningmastery.com/machine-learning-in-python-step-by-step/">Machine learning mastery blog</a> cho thấy tác giả áp dụng rất tốt nguyên tắc này, qua việc tác giả đã cố gắng sử dụng hàm nhiều nhất có thể, ví dụ <code>train_test_split</code>, <code>accuracy_score</code> và <code>confusion_matrix</code>, khi đó chuyện test và debug sẽ dễ dàng hơn rất nhiều.</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make predictions</span></span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="comment"># Load dataset</span></span><br><span class="line">url = <span class="string">&quot;https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv&quot;</span></span><br><span class="line">names = [<span class="string">&#x27;sepal-length&#x27;</span>, <span class="string">&#x27;sepal-width&#x27;</span>, <span class="string">&#x27;petal-length&#x27;</span>, <span class="string">&#x27;petal-width&#x27;</span>, <span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">dataset = read_csv(url, names=names)</span><br><span class="line"><span class="comment"># Split-out validation dataset</span></span><br><span class="line">array = dataset.values</span><br><span class="line">X = array[:,<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">y = array[:,<span class="number">4</span>]</span><br><span class="line">X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=<span class="number">0.20</span>, random_state=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Make predictions on validation dataset</span></span><br><span class="line">model = SVC(gamma=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">model.fit(X_train, Y_train)</span><br><span class="line">predictions = model.predict(X_validation)</span><br><span class="line"><span class="comment"># Evaluate predictions</span></span><br><span class="line">print(accuracy_score(Y_validation, predictions))</span><br><span class="line">print(confusion_matrix(Y_validation, predictions))</span><br><span class="line">print(classification_report(Y_validation, predictions))</span><br></pre></td></tr></table></figure></li><li><p><strong>Regression testing:</strong> kiểm tra lại toàn bộ chức năng của hệ thống mỗi khi có thay đổi của một hoặc vài chức năng nào đó</p></li><li><p><strong>Smoke testing:</strong> chạy một bài test cơ bản với chức năng tối thiểu để xem hệ thống sẵn sàng cho việc test chưa<br> Một ví dụ đơn giản: Bắt đầu kiểm tra một hệ thống bóng đèn, vừa ấn nút xong khói (smoke) bốc lên nghi ngút thì khỏi test tiếc gì thêm.</p></li></ol><h4 id="Non-functional-Testing"><a href="#Non-functional-Testing" class="headerlink" title="Non-functional Testing"></a>Non-functional Testing</h4><ol><li><strong>Load testing:</strong> xác định độ chịu tải, SLA của hệ thống</li><li><strong>Stress testing:</strong> đánh giá hành vi của hệ thống tại các điều kiện không lường trước, ví dụ một phần hệ thống đột nhiên shutdown thì phản hồi có chấp nhận được không</li></ol><h4 id="Luong-phat-trien-phan-mem-co-ban"><a href="#Luong-phat-trien-phan-mem-co-ban" class="headerlink" title="Luồng phát triển phần mềm cơ bản"></a>Luồng phát triển phần mềm cơ bản</h4><p>Thông thường, các developer tuân thủ một số quy ước sau khi phát triển phần mềm:</p><ol><li>Không merge code nếu chưa chạy các test case</li><li>Luôn viết code test khi commit logic mới</li><li>Khi fix bug, luôn viết code test để bắt bug, và phòng xảy ra trường hợp tương tự trong tương lai</li></ol><img src="typical_workflow_se.jpeg" alt="Typical SE development workflow" width="600" height="150" /><figcaption align="center" font-size="8px"><i>Source: https://www.jeremyjordan.me/testing-ml/</i></figcaption><h3 id="He-thong-ML-can-kiem-thu-nhung-gi"><a href="#He-thong-ML-can-kiem-thu-nhung-gi" class="headerlink" title="Hệ thống ML cần kiểm thử những gì?"></a>Hệ thống ML cần kiểm thử những gì?</h3><p>Những bài test cho hệ thống phần mềm có thể ứng dụng cho hầu hết ML code, tuy nhiên vẫn chưa để đủ đảm bảo hệ thống ML có thể hoạt động với độ tin cậy cao. </p><img src="difference.png" alt="ML testing differences" width="600" height="300" /><figcaption align="center" font-size="8px"><i>Source: https://learning.oreilly.com/library/view/building-machine-learning</i></figcaption><p>OK! Thế để hệ thống ML tin tưởng được thì cần kiểm tra thêm những gì?</p><ul><li><strong>Data pipeline testing:</strong> đảm bảo dữ liệu không bị corrupt, đúng format và đúng schema (kiểu dữ liệu), …</li><li><strong>Model testing:</strong> đảm bảo model đạt hiểu quả (ví dụ accuracy) như mong muốn và model có consistent không, …</li></ul><ol><li><strong>Data pipeline testing</strong><br>Data là một phần không thể thiếu trong một hệ thống ML, do đó duy trì một data pipeline với độ tin cậy cao là điều rất quan trọng.<br>Hình dưới đây là ví dụ về 1 data pipeline và những thứ yếu tố cần cân nhắc ở mỗi bước:</li></ol><img src="data_pipeline_testing.png" alt="Data pipeline testing" width="600" height="300" /><ol start="2"><li><strong>Model testing</strong><br>Có thể chia thành 2 loại model testing:</li></ol><ul><li><p><strong>Testing</strong></p><ul><li><p><strong>Pre-train testing:</strong> tìm bug trước khi train/evaluate</p><ul><li>Kiểm tra xem có data leakage (leak thông tin), ví dụ observation trong tập train cũng có ở tập validation/test</li><li>Kiểm tra xem có feature leakage (feature mang thông tin của label)</li><li>Kiểm tra model output có shape, hoặc có miền giá trị như ý muốn</li></ul></li><li><p><strong>Post-train testing:</strong> hoạt động của model (model behavior) có như ý muốn ở các tình huống (scenarios) khác nhau?</p><ul><li><strong>Invariance testing:</strong> mô tả những thay đổi của input mà không làm thay đổi kết quả dự đoán của model<br>  Ví dụ: trong bài toán sentiment analysis, thì 2 câu sau nên có cùng một output:<ul><li>Bộ phim A hay quá!</li><li>Bộ phim B hay quá!</li></ul></li><li><strong>Directional expectation test:</strong> mô tả những thay đổi của input sẽ làm thay đổi kết quả dự đoán của model một cách có thể lường trước.<br>  Ví dụ: trong bài toán dự đoán giá nhà, có thể đoán trước nếu không gian tăng, thì giá nhà sẽ tăng.</li><li><strong>Bias/Fairness:</strong> kiểm tra xem model có dự đoán công bằng không, ví dụ dự đoán income của người châu Mỹ chính xác hơn người châu Á, chứng tỏ model đang bị bias.</li><li><strong>Model Output Consistency:</strong> với cùng 1 dữ liệu đầu vào, model output có bị thay đổi sau nhiều lần chạy khác nhau không?</li></ul><p>  <strong>Note:</strong> Công cụ <a href="https://pair-code.github.io/what-if-tool/">What-If</a> hỗ trợ rất tốt trong việc kiểm tra model behavior ở các tình huống khác nhau.</p></li></ul></li><li><p><strong>Evaluation:</strong> đánh giá hiệu quả của model thông qua các metrics như accuracy và F1, … trên tập validation/test.</p></li></ul><h3 id="Mot-so-tool-hay-dung-de-test-va-debug"><a href="#Mot-so-tool-hay-dung-de-test-va-debug" class="headerlink" title="Một số tool hay dùng để test và debug"></a>Một số tool hay dùng để test và debug</h3><ul><li><a href="https://docs.python.org/3/library/pdb.html">pdb</a> để debug python code</li><li><a href="https://docs.pytest.org/en/6.2.x/">pytest</a> là framework hỗ trợ viết code test</li><li><a href="https://coverage.readthedocs.io/en/coverage-5.5/#:~:text=Coverage.py%20is%20a%20tool,gauge%20the%20effectiveness%20of%20tests.">Coverage.py</a> để xác định đoạn code nào có thể được execute nhưng đã không</li><li><a href="https://www.pylint.org/">pylint</a> để kiểm tra lỗi cú pháp/logic</li></ul><h3 id="Tai-lieu-tham-khao"><a href="#Tai-lieu-tham-khao" class="headerlink" title="Tài liệu tham khảo"></a>Tài liệu tham khảo</h3><p>[1] <a href="https://serokell.io/blog/machine-learning-testing">https://serokell.io/blog/machine-learning-testing</a><br>[2] <a href="https://developers.google.com/machine-learning/testing-debugging/common/overview">https://developers.google.com/machine-learning/testing-debugging/common/overview</a><br>[3] Emmanuel Ameisen, Building Machine Learning Powered Applications: Going from Idea to Product<br>[4] <a href="https://www.jeremyjordan.me/testing-ml/">https://www.jeremyjordan.me/testing-ml/</a><br>[5] <a href="https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf">https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf</a><br>[6] <a href="https://fontysblogt.nl/software-engineering-for-machine-learning-applications/">https://fontysblogt.nl/software-engineering-for-machine-learning-applications/</a><br>[7] <a href="https://futurice.com/blog/differences-between-machine-learning-and-software-engineering">https://futurice.com/blog/differences-between-machine-learning-and-software-engineering</a><br>[8] <a href="https://www.geeksforgeeks.org/differences-between-functional-and-non-functional-testing/">https://www.geeksforgeeks.org/differences-between-functional-and-non-functional-testing/</a><br>[9] <a href="https://eugeneyan.com/writing/testing-ml/">https://eugeneyan.com/writing/testing-ml/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> mlops </tag>
            
            <tag> ml-testing </tag>
            
            <tag> testing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tổng quan về hệ thống Machine Learning</title>
      <link href="2021/08/01/ml-system-overview/"/>
      <url>2021/08/01/ml-system-overview/</url>
      
        <content type="html"><![CDATA[<p>Hồi mới nhận nhiệm vụ triển khai hệ thống ML, mình cứ nghĩ là chắc build một Web API đơn giản là xong. Tuy nhiên khi thực sự bắt tay vào làm, cộng thêm đọc tài liệu trên trời dưới đất, mình mới chợt nhận ra là “Ôi thôi ngu rồi, API chỉ là một phần nhỏ xíu thôi”. Hy vọng bài viết này giúp mọi người có cái nhìn tổng quan hơn về một hệ thống ML, để khi nhận task đỡ bỡ ngỡ…</p><img src="sad-smile.jpeg" alt="ML system overview meme" width="300" height="200" /><p>Do tính tình bộc trực thẳng thắn nên mình xin phép đi thẳng vào vấn đề chính bằng cách ném toẹt bức ảnh tổng quan về hệ thống ML ở đây luôn.</p><img src="ml-sys.png" alt="ML system overview" width="630" height="500" /><p>Ở đây, ngoài môi trường để Data Scientist (DS) thử nghiệm model, mình dùng thêm 2 môi trường là staging và production.</p><h3 id="1-Moi-truong-staging"><a href="#1-Moi-truong-staging" class="headerlink" title="1. Môi trường staging"></a>1. Môi trường staging</h3><ul><li>Thực hiện unit test để đảm bảo tính chính xác của các hàm riêng lẻ</li><li>Thực hiện integration test để khi kết hợp các hàm với nhau không xảy ra vấn đề gì</li><li>Test training pipeline với dữ liệu staging (dữ liệu giả, hoặc lấy một phần dữ liêụ production) để xem có lỗi không<br>  <strong>Ví dụ:</strong> Lỗi pipeline không trả ra model, lỗi thiếu quyền truy cập vào các tài nguyên cloud (GCS,S3), …</li><li>Test luồng từ khi model được upload lên model registry cho tới khi serve model<br>  <strong>Ví dụ:</strong> Online serving có serve được request và trả ra kết quả đúng như dự đoán không</li></ul><h3 id="2-Moi-truong-production"><a href="#2-Moi-truong-production" class="headerlink" title="2. Môi trường production"></a>2. Môi trường production</h3><ul><li>Thực hiện train với dữ liệu production, và retrain tuỳ theo bài toán<br>  <strong>Ví dụ:</strong> Với dữ liệu training biến đổi nhiều thì retrain hàng ngày, còn nếu ít thì chỉ retrain khi nhận được event báo có sự thay đổi nhiều trong phân bố của training data </li><li>Thu thập ML metadata, ví dụ:<ul><li>Training pipeline metadata: ghi lại thời gian retrain, phân bố của dữ liệu training, kết quả model trên tập validation</li><li>Serving metadata: thông tin các model đang được serve hiện tại, hoặc model đang được A/B test</li></ul></li><li>Trả về kết quả dự đoán (có thể kèm giải thích cho dự đoán tuỳ model và bài toán) cho user, và lưu lại log để phân tích thêm<br>  Có 2 cách thức serve phổ biến<ul><li>Online serving: dự đoán mỗi khi có request đến</li><li>Offline batch serving: dự đoán trên toàn bộ dữ liệu, và mỗi khi có request, chỉ cần trả query kết quả dự đoán tương ứng</li></ul></li><li>Monitor hệ thống<br>  <strong>Ví dụ:</strong> monitor tình trạng CPU, GPU để scale tài nguyên lên hoặc xuống cho phù hợp, hoặc monitor thời gian phản hồi của model xem có bị chậm không</li><li>Monitor model: sử dụng log của bước dự đoán, kết hợp cùng dữ liệu có sẵn (ví dụ label cho user) để đánh giá xem model đã bị giảm performance chưa, hoặc có sự biến đổi nhiều trong phân bố của kết quả dự đoán không, vân vân và mây mây</li></ul><h3 id="3-Ket-luan"><a href="#3-Ket-luan" class="headerlink" title="3. Kết luận"></a>3. Kết luận</h3><ul><li> Hệ thống ML không chỉ đơn giản là làm xong một Web API rồi ném đấy. Mình cần xem xét các yếu tố khác, ví dụ như làm sao để quá trình từ lúc model còn đang ở môi trường research lên môi trường production nhanh nhất, hoặc khi nào thì cần thay thế một model đang trên production rồi, và thay thế như nào để giảm downtime, và nhiều thứ khác</li><li>Tuỳ từng yêu cầu bài toàn, mà hệ thống ML sẽ được phát triển theo các hướng khác nhau, với các thành phần khác nhau, do đó nên xác định rõ yêu cầu và timeline từ đầu, để có định hướng xây dựng hệ thống phù hợp</li></ul><h3 id="4-Tai-lieu-tham-khao"><a href="#4-Tai-lieu-tham-khao" class="headerlink" title="4. Tài liệu tham khảo"></a>4. Tài liệu tham khảo</h3><ol><li><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning">https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning</a></li><li><a href="https://github.com/mercari/ml-system-design-pattern">https://github.com/mercari/ml-system-design-pattern</a></li><li><a href="https://stanford-cs329s.github.io/">https://stanford-cs329s.github.io/</a></li><li><a href="https://docs.seldon.io/projects/seldon-core/en/latest/">https://docs.seldon.io/projects/seldon-core/en/latest/</a></li><li>Michael Munn, Sara Robinson, and Valliappa Lakshmanan: Machine Learning Design Patterns (2020)</li></ol><p>Bài viết đã dài phết rồi, mình xin được dừng bút tại đây. Mình sẽ cố gắng viết cụ thể hơn về từng thành phần trong các bài sau, mọi người nhớ đón đọc và thả tim nha. Cảm ơn mọi người và chúc mọi người giữ vững sức khoẻ trong mùa dịch :D.</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning system </tag>
            
            <tag> mlops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge Distillation với PyTorch</title>
      <link href="2021/01/24/knowledge-distillation-using-pytorch/"/>
      <url>2021/01/24/knowledge-distillation-using-pytorch/</url>
      
        <content type="html"><![CDATA[<div style="text-align: center"> Knowledge Distillation (KD) là một kỹ thuật nén model (model compression) sao cho độ chính xác (hoặc một thước đo khác như mAP, và F1-score, ...) không thay đổi nhiều so với model gốc. </div><p><img src="/2021/01/24/knowledge-distillation-using-pytorch/teach-me.jpg" alt="Random Forests meme"></p><h3 id="Bai-toan-thuc-te"><a href="#Bai-toan-thuc-te" class="headerlink" title="Bài toán thực tế"></a>Bài toán thực tế</h3><p>Nén model phân loại chữ viết tay sử dụng kỹ thuật KD, với bộ dữ liệu <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></p><h4 id="Buoc-1-Import-cac-thu-vien-can-thiet"><a href="#Buoc-1-Import-cac-thu-vien-can-thiet" class="headerlink" title="Bước 1: Import các thư viện cần thiết"></a>Bước 1: Import các thư viện cần thiết</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> vstack</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure><h4 id="Buoc-2-Load-du-lieu"><a href="#Buoc-2-Load-du-lieu" class="headerlink" title="Bước 2: Load dữ liệu"></a>Bước 2: Load dữ liệu</h4><p>Ở bước này chúng ta sẽ load bộ dữ liệu MNIST,và biến đổi dữ liệu sao cho model có thể sử dụng được. Lưu ý rằng bộ dữ liệu này có sẵn trong thư viện torchvision rồi, nên chỉ cần load lên mà không cần vào trang chủ của bộ dữ liệu để tải nha. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># định nghĩa phép chuyển đổi: thay đổi kích thước ảnh thành 32x32, và chuyển đổi</span></span><br><span class="line"><span class="comment"># dữ liệu sang dạng tensor</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">                                transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">                                transforms.ToTensor(),</span><br><span class="line">                                ])</span><br><span class="line"><span class="comment"># load tập dữ liệu train và test, và áp dụng phép chuyển đổi cho tập dữ liệu</span></span><br><span class="line">train_set = MNIST(root=<span class="string">&#x27;tmp/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_set = MNIST(root=<span class="string">&#x27;tmp/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tạo loader để truyền vào model dữ liệu theo batch</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_set, batch_size=<span class="number">128</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h4 id="Buoc-3-Xay-dung-cac-model"><a href="#Buoc-3-Xay-dung-cac-model" class="headerlink" title="Bước 3: Xây dựng các model"></a>Bước 3: Xây dựng các model</h4><p>Chúng ta sẽ xây dựng 2 model ở bước này:</p><ul><li>Model giáo viên (teacher): model gốc (LeNet5)</li><li>Model học sinh (student): model sau khi nén bằng cách giữ nguyên số lượng layer, nhưng giảm số lượng tham số (parameters)</li></ul><h5 id="Model-giao-vien"><a href="#Model-giao-vien" class="headerlink" title="Model giáo viên"></a>Model giáo viên</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Teacher</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># Ref: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html</span></span><br><span class="line">        <span class="built_in">super</span>(Teacher, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 3x3 square convolution</span></span><br><span class="line">        <span class="comment"># kernel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">120</span>)  <span class="comment"># 6*6 from image dimension</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br></pre></td></tr></table></figure><h5 id="Model-hoc-sinh"><a href="#Model-hoc-sinh" class="headerlink" title="Model học sinh"></a>Model học sinh</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Student, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 3x3 square convolution</span></span><br><span class="line">        <span class="comment"># kernel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">12</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">12</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">90</span>)  <span class="comment"># 6*6 from image dimension</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">90</span>, <span class="number">64</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), <span class="number">2</span>)</span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br></pre></td></tr></table></figure><h4 id="Buoc-3-Train-cac-model"><a href="#Buoc-3-Train-cac-model" class="headerlink" title="Bước 3: Train các model"></a>Bước 3: Train các model</h4><h5 id="Model-giao-vien-1"><a href="#Model-giao-vien-1" class="headerlink" title="Model giáo viên"></a>Model giáo viên</h5><p>Đầu tiên chúng ta sẽ định nghĩa hàm loss và optimizer cho model như sau:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(teacher.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>Sau đó train model 100 epochs;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = teacher(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">99</span>:    <span class="comment"># print every 100 mini-batches</span></span><br><span class="line">            print(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> %</span><br><span class="line">                  (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">100</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">print(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure><h5 id="Model-hoc-sinh-1"><a href="#Model-hoc-sinh-1" class="headerlink" title="Model học sinh"></a>Model học sinh</h5><p>Ngoài định nghĩa hàm loss và optimizer như model giáo viên, chúng ta sẽ khai báo thêm 2 tham số cố định $alpha$ và $temperature$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.1</span></span><br><span class="line">temperature = <span class="number">10</span></span><br></pre></td></tr></table></figure><p>Và train model 50 epochs:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">          teacher_pred = teacher(inputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        student_pred = student(inputs)</span><br><span class="line"></span><br><span class="line">        student_loss = criterion(student_pred, labels)</span><br><span class="line">        </span><br><span class="line">        distillation_loss = F.kl_div(</span><br><span class="line">            F.log_softmax(teacher_pred / temperature, dim=<span class="number">1</span>),</span><br><span class="line">            F.softmax(student_pred / temperature, dim=<span class="number">1</span>),</span><br><span class="line">            reduction=<span class="string">&#x27;batchmean&#x27;</span>        </span><br><span class="line">        )</span><br><span class="line">        loss = alpha * student_loss + (<span class="number">1</span> - alpha) * distillation_loss</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">99</span>:    <span class="comment"># print every 100 mini-batches</span></span><br><span class="line">            print(<span class="string">&#x27;[&#123;&#125;, &#123;&#125;] loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">100</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">print(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>Lưu ý một vài thay đổi so với model giáo viên:</strong> </p><table><thead><tr><th align="center"><img src="/2021/01/24/knowledge-distillation-using-pytorch/knowledge_distillation.png" alt="Knowledge Distillation"></th></tr></thead><tbody><tr><td align="center"><em>Nguồn: <a href="https://intellabs.github.io/distiller/knowledge_distillation.html">https://intellabs.github.io/distiller/knowledge_distillation.html</a></em></td></tr></tbody></table><ul><li>model học sinh sử dụng thêm 1 loại loss nữa, đó là $distillation\ loss$, được tính bằng <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a> giữa phân phối của model giáo viên và model học sinh.</li><li>Tham số $alpha$ dùng để đánh trọng số (weight) cho $student\ loss$ và $distillation\ loss$.</li><li>Tham số $temperature$ có tác dụng làm phân phối “soft” hơn. Tham số này càng tăng, thì phân phối càng “soft”, như hình dưới đây:</li></ul><p><img src="/2021/01/24/knowledge-distillation-using-pytorch/smoothen.png" alt="Smooth Distribution"></p><h3 id="Tai-sao-khong-train-model-hoc-sinh-tu-dau"><a href="#Tai-sao-khong-train-model-hoc-sinh-tu-dau" class="headerlink" title="Tại sao không train model học sinh từ đầu?"></a>Tại sao không train model học sinh từ đầu?</h3><p>Chúng ta hoàn toàn có thể train model học sinh từ đầu, tuy nhiên sẽ khó đạt được kết quả như kỳ vọng. Kỹ thuật KD giúp model học sinh:</p><ul><li>Generalize tốt hơn, do tập train của model giáo viên thông thường sẽ lớn hơn nhiều so với tập train của model học sinh</li><li>$distillation\ loss$ giảm thiểu ảnh hưởng của việc phân bố tập train của model học sinh khác nhiều so với phân bố thực tế</li></ul><h3 id="Tai-lieu-tham-khao"><a href="#Tai-lieu-tham-khao" class="headerlink" title="Tài liệu tham khảo"></a>Tài liệu tham khảo</h3><p>[1] <a href="https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764">https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764</a><br>[2] <a href="https://keras.io/examples/vision/knowledge_distillation/">https://keras.io/examples/vision/knowledge_distillation/</a><br>[3] <a href="https://intellabs.github.io/distiller/knowledge_distillation.html">https://intellabs.github.io/distiller/knowledge_distillation.html</a><br>[4] <a href="https://arxiv.org/abs/1503.02531">https://arxiv.org/abs/1503.02531</a><br>[5] <a href="https://thenextweb.com/neural/2020/10/26/how-knowledge-distillation-compresses-neural-networks-syndication/">https://thenextweb.com/neural/2020/10/26/how-knowledge-distillation-compresses-neural-networks-syndication/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> knowledge distillation </tag>
            
            <tag> model compression </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Decision Trees</title>
      <link href="2021/01/18/decision-trees-dts/"/>
      <url>2021/01/18/decision-trees-dts/</url>
      
        <content type="html"><![CDATA[<div style="text-align: center"> Decision Trees là một trong những thuật toán phổ biến trong Machine Learning, là tiền đề để phát triển các thuật toán phức tạp hơn như Random Forest, XGBoost và LightGBM. Hôm nay mình sẽ cùng nhau tìm hiểu thuật toán này nhé. </div><p><img src="https://hackernoon.com/hn-images/1*6-ctYxKmTS8v0RzwLILfXA.png" alt="Random Forests meme"></p><h3 id="Bai-toan-thuc-te"><a href="#Bai-toan-thuc-te" class="headerlink" title="Bài toán thực tế"></a>Bài toán thực tế</h3><h4 id="Phan-loai-hoa-voi-tap-du-lieu-iris"><a href="#Phan-loai-hoa-voi-tap-du-lieu-iris" class="headerlink" title="Phân loại hoa với tập dữ liệu iris"></a>Phân loại hoa với <a href="https://archive.ics.uci.edu/ml/datasets/iris">tập dữ liệu iris</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># load dữ liệu iris</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tách features (X) và label (y)</span></span><br><span class="line">X = iris.data[:, <span class="number">2</span>:]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># chia dữ liệu thành 2 tập train và test, với tỷ lệ </span></span><br><span class="line"><span class="comment"># tập test là 0.2</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xây dựng model</span></span><br><span class="line">clf = DecisionTreeClassifier(max_depth=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># train model</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dự đoán trên tập test</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># đánh giá kết quả dựa trên accuracy score</span></span><br><span class="line">print(<span class="string">&quot;[INFO] accuracy score: &quot;</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><h4 id="Du-doan-gia-nha-voi-tap-du-lieu-boston"><a href="#Du-doan-gia-nha-voi-tap-du-lieu-boston" class="headerlink" title="Dự đoán giá nhà với tập dữ liêu boston"></a>Dự đoán giá nhà với <a href="https://www.kaggle.com/vikrishnan/boston-house-prices">tập dữ liêu boston</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># load dữ liệu boston</span></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tách features (X) và label (y)</span></span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># chia dữ liệu thành 2 tập train và test, với tỷ lệ </span></span><br><span class="line"><span class="comment"># tập test là 0.2</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xây dựng model</span></span><br><span class="line">clf = DecisionTreeRegressor(max_depth=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># train model</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dự đoán trên tập test</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># đánh giá kết quả dựa trên r2_score</span></span><br><span class="line">print(<span class="string">&quot;[INFO] r2_score: &quot;</span>, r2_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><h3 id="Y-tuong-thuat-toan"><a href="#Y-tuong-thuat-toan" class="headerlink" title="Ý tưởng thuật toán"></a>Ý tưởng thuật toán</h3><p>Hiểu đơn giản là thuật toán xây dựng một cây quyết định, liên tục phân chia tập dữ liệu về các nhánh. Thuật toán này có thể dùng cho cả bài toán phân loại (classification) và hồi quy (regression).</p><p>Có nhiều phương pháp implement thuật toán Decision Trees, ví dụ như ID3, C4.5, C5.0 và CART. Thư viện sklearn sử dụng phiên bản tối ưu của CART.</p><h4 id="Phan-loai"><a href="#Phan-loai" class="headerlink" title="Phân loại"></a>Phân loại</h4><p>Trở lại bài toán phân loại hoa, sử dụng đoạn code dưới đây để xem cây quyết định trông thế nào nhé.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">dot_data = export_graphviz(</span><br><span class="line">            clf,</span><br><span class="line">            out_file=<span class="literal">None</span>,</span><br><span class="line">            feature_names=iris.feature_names,</span><br><span class="line">            class_names=iris.target_names,</span><br><span class="line">            rounded=<span class="literal">True</span>,</span><br><span class="line">            filled=<span class="literal">True</span>,</span><br><span class="line">            special_characters=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line"><span class="comment"># lưu graph ra file graph.png</span></span><br><span class="line">graph.render(<span class="string">&quot;iris-tree&quot;</span>, <span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>)</span><br><span class="line"><span class="comment"># hiển thị graph</span></span><br><span class="line">graph</span><br></pre></td></tr></table></figure><p>Và bing-go, cây sẽ như này nè:</p><p><img src="/2021/01/18/decision-trees-dts/iris-tree.png" alt="iris tree"></p><p><strong>Giải thích cây quyết định:</strong> </p><ul><li><p>Bắt đầu từ node trên cùng (hay node root), với điều kiện $petal\ width \leq 0.8$, dữ liệu nào thỏa mãn điều kiện sẽ đi về nhánh trái, còn lại sẽ đi về nhánh phải. Node màu cam không có nhánh con nào nên được gọi là node lá, và dữ liệu ở node này sẽ được kết luận luôn là thuộc class setosa. Node màu xám (có nhánh con nên được gọi là node phân chia hay splitting node) tiếp tục phân chia tập dữ liệu thuộc node này về 2 node xanh và tím dựa trên điều kiện $petal\ length \leq 4.75$</p></li><li><p>Một số thông tin khác của node bao gồm:</p><ul><li><p>gini: mô tả “độ thuần khiết” (impurity) của node, dao động từ 0 đến 1. Trong đó 0 nghĩa là tất cả dữ liệu thuộc cùng 1 class, nên chúng ta luôn muốn <strong>gini</strong> nhỏ nhất có thể </p><p>  Công thức tính <strong>gini</strong> cho node $i$ như sau: $G_i = 1-\sum_{k=1}^{n}p_{i,k}^2$</p><p>  Trong đó: </p><ul><li><p>$p_{i,k}$ là tỉ lệ số phần tử của class k trên tổng số samples.</p><p>  Ví dụ: ở node màu tím, $G=1-(0/43)^2-(5/43)^2-(38/43)^2\approx0.206$</p></li></ul></li><li><p>samples: số lượng dữ liệu training thuộc node</p></li><li><p>value: số lượng dữ liệu của từng class trong node, ví dụ node tím có 0 setosa, 5 versicolor và 38 virginica </p></li></ul></li></ul><h4 id="Hoi-quy"><a href="#Hoi-quy" class="headerlink" title="Hồi quy"></a>Hồi quy</h4><p>Cây quyết định cho bài toán dự đoán giá nhà như sau:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">dot_data = export_graphviz(</span><br><span class="line">            clf,</span><br><span class="line">            out_file=<span class="literal">None</span>,</span><br><span class="line">            feature_names=boston.feature_names,</span><br><span class="line">            rounded=<span class="literal">True</span>,</span><br><span class="line">            filled=<span class="literal">True</span>,</span><br><span class="line">            special_characters=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line"><span class="comment"># lưu graph ra file graph.png</span></span><br><span class="line">graph.render(<span class="string">&quot;boston-tree&quot;</span>, <span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>)</span><br><span class="line"><span class="comment"># hiển thị graph</span></span><br><span class="line">graph</span><br></pre></td></tr></table></figure><p><img src="/2021/01/18/decision-trees-dts/boston-tree.png" alt="boston tree"></p><p>Cây quyết định cho bài toán hồi quy khá giống với phân loại, ngoại trừ:</p><ul><li><p><strong>gini</strong> được thay bằng <strong>MSE</strong></p><p>  Công thức tính <strong>MSE</strong> cho node $i$ như sau: $MSE_i = \sum_{i\in node}(y_i - \bar{y})^2$</p><p>  Trong đó: </p><ul><li>$y_i$ là label của từng phần tử trong node</li><li>$\bar{y} = \frac{1}{tổng\ số \ phần\ tử\ của\ node}\sum_{i\in node}y_i$</li></ul></li><li><p>dự đoán value, thay vì class</p></li></ul><h3 id="Phuong-phap-CART"><a href="#Phuong-phap-CART" class="headerlink" title="Phương pháp CART"></a>Phương pháp CART</h3><ol><li><p>Bước 1: chia tập dữ liệu thành 2 tập con sử dụng feature $k$ và giá trị $t_k$, sao cho hàm cost dưới đây là nhỏ nhất<br> $J(k,t_k)=\frac{m_{trái}}{m}G_{trái}+\frac{m_{phải}}{m}G_{phải}$</p><p> Trong đó:</p><ul><li>$m_{trái}$ và $m_{phải}$ là số lượng dữ liệu của 2 node trái và phải (2 tập con)</li><li>$m$ là số lượng dữ liệu ở node hiện tại</li><li>$G_{trái}$ và $G_{phải}$ là <strong>gini</strong> của 2 node trái và phải</li></ul></li><li><p>Bước 2: tiếp tục phân chia các tập con sử dụng logic tương tự bước trên, cho tới khi thỏa mãn điều kiện dừng, ví dụ như:</p><ul><li>đạt độ sâu tối đa (quy định bởi hyperparameter <strong>max_depth</strong>)</li><li>không thể phân chia sao cho <strong>gini</strong> của các tập con nhỏ hơn tập gốc</li></ul></li></ol><h3 id="Tai-lieu-tham-khao"><a href="#Tai-lieu-tham-khao" class="headerlink" title="Tài liệu tham khảo"></a>Tài liệu tham khảo</h3><p>[1] Aurlien Gron. 2020. Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (2nd. ed.). O’Reilly Media, Inc.<br>[2] Brownlee, J. (2016) Machine Learning Mastery with Python. Machine Learning Mastery, EBook.<br>[3] <a href="https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052">https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> decision trees </tag>
            
            <tag> random forest </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
